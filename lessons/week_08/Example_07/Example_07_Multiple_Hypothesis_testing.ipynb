{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "KydhnP7NFsVa"
      },
      "source": [
        "\n",
        "\n",
        "# 1.0 Multiple hypothesis testing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this notebook we will study a method of correcting for multiple hypothesis testing, which occurs often in practice when searching for anomalies in multiple datasets.\n",
        "\n",
        "Let's start from the basics and illustrate what does it mean to have multiple tests.\n",
        "\n",
        "Roughly speaking, a statistical test is something capable of either **rejecting** or **not the null hypothesis** with a given type I error probability $\\alpha$ (probability of a false positive) and a type II error probability $\\beta$ (probability of a false negative).\n",
        "\n",
        "If you need a refresher, look in your favorite textbook or on [Wikipedia](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)."
      ],
      "metadata": {
        "id": "tQuC8U0BF9p_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "-GzGdvFOFsVd"
      },
      "source": [
        "## 1.1 Our toy problem\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's consider the problem of determining whether two populations have the same average or not. The **null hypothesis** is that the average is the same, the alternative is that it is not. \n",
        "\n",
        "Note that you can substitute this problem with any other problem answerable with a statistical test and all the discussion here will still hold (but of course you need to rework the code)."
      ],
      "metadata": {
        "id": "_VjtKfekGcRD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eVBvb7AuFsVd"
      },
      "source": [
        "## 1.2 Simple case: one test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "BoFTXDSyFsVe"
      },
      "source": [
        "The test appropriate for the problem at hand is the [Student's T-test](https://en.wikipedia.org/wiki/Student%27s_t-test). Let's write the function that computes the p-value and a function that decides whether the null is rejected or not based on the p-value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "dTJ8d1eSFsVe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.stats\n",
        "\n",
        "# Let's write so that w1 and w2 can be lists of n\n",
        "# datasets, from 1 to as much as needed\n",
        "def apply_ttest(w1, w2):\n",
        "    \n",
        "    ts, pvalues = scipy.stats.ttest_ind(w1, w2, axis=1)\n",
        "\n",
        "    return np.squeeze(pvalues)\n",
        "\n",
        "# The null is accepted if all the pvalues are larger \n",
        "# than alpha (global null hypothesis, see below)\n",
        "def null_hyp_status(pvalue, alpha):\n",
        "    \n",
        "    return np.all(pvalue > alpha)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(n_datasets, n_null_true, n_samples=100, seed=0):\n",
        "    \n",
        "    # This is to make the results predictable\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    n_null_false = n_datasets - n_null_true\n",
        "    \n",
        "    w1 = []\n",
        "    w2 = []\n",
        "    null_status = []\n",
        "    \n",
        "    for i in range(n_null_true):\n",
        "        \n",
        "        wn_1 = np.random.normal(loc=90, scale=10, size=n_samples)\n",
        "        wn_2 = np.random.normal(loc=90, scale=10, size=n_samples)\n",
        "    \n",
        "        w1.append(wn_1)\n",
        "        w2.append(wn_2)\n",
        "        \n",
        "        null_status.append(True)\n",
        "    \n",
        "    for i in range(n_null_false):\n",
        "        \n",
        "        wn_1 = np.random.normal(loc=95, scale=10, size=n_samples)\n",
        "        wn_2 = np.random.normal(loc=90, scale=10, size=n_samples)\n",
        "    \n",
        "        w1.append(wn_1)\n",
        "        w2.append(wn_2)\n",
        "        null_status.append(False)\n",
        "    \n",
        "    return w1, w2, np.array(null_status)"
      ],
      "metadata": {
        "id": "Y3LhNKXSHrR9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "oKY6IL7wFsVf"
      },
      "source": [
        "We now generate 1 dataset with the null hypothesis true, and apply the test. We will use a type I error probability $\\alpha=0.05$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ax_073SFsVf",
        "outputId": "1b38be0e-5505-40c4-9c6d-d6a43165aa21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null hyp. is deemed True (p_value = 0.878587)\n"
          ]
        }
      ],
      "source": [
        "# Let's get a dataset with 1 group and\n",
        "# the null hypothesis is true\n",
        "w1, w2, ground_truth = generate_dataset(n_datasets=1, n_null_true=1)\n",
        "\n",
        "# Let's now apply the test\n",
        "alpha = 0.05\n",
        "pvalue = apply_ttest(w1, w2)\n",
        "\n",
        "print(\"Null hyp. is deemed %s (p_value = %f)\" % (null_hyp_status(pvalue, alpha),pvalue))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "dyuVb4jSFsVg"
      },
      "source": [
        "The test worked as expected, and didn't reject the null hypothesis (which we know is true). Let's verify that the performance of the test is nominal, i.e., that by repeating a large number of independent realizations of the same experiment we reject by chance the null hypothesis with the nominal type I error probability $\\alpha$:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now apply the test\n",
        "alpha = 0.05\n",
        "\n",
        "# Times the test was rejected\n",
        "rejected = 0\n",
        "\n",
        "# Number of iterations\n",
        "iter = 5000\n",
        "\n",
        "for i in range(iter):\n",
        "    seed = (i+1) * 1000\n",
        "    w1, w2, ground_truth = generate_dataset(n_datasets=1, n_null_true=1, seed=seed)\n",
        "\n",
        "    pvalue = apply_ttest(w1, w2)\n",
        "\n",
        "    if not null_hyp_status(pvalue, alpha):\n",
        "        rejected += 1\n",
        "\n",
        "print(\"\\nMeasured chance probability of rejecting the \"\n",
        "      \"null: %.3f (should be %.3f)\" % (rejected/iter, alpha))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMITatT3M6xC",
        "outputId": "dae4f825-8591-4518-ed0a-49e2032f031f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Measured chance probability of rejecting the null: 0.052 (should be 0.050)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "ootDz-P-FsVh"
      },
      "source": [
        "ok, it works as expected.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Multiple tests\n"
      ],
      "metadata": {
        "id": "NLv2KBB9P-N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Let's now imagine that we have $m$ pairs of populations, and we want to find out whether one or more pairs have a significant difference between the populations.\n",
        "\n",
        "- The null hypothesis here is \"within all pairs, the two populations have the same average\".\n",
        "- The alternative one is \"there is at least one pair where the average is different between the two populations\".\n",
        "\n",
        "Can we just apply the test separately to each pair and see if it rejects for at least one? (spoiler: the answer is no! Also, let's neglect the fact that there are other tests designed for this situation, like ANOVA). Let's see:"
      ],
      "metadata": {
        "id": "mcSdVyTkP_5r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xZplsh9FsVh",
        "outputId": "4bb3caa4-44b6-4cae-c783-e622106e1f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null hyp. is deemed False\n"
          ]
        }
      ],
      "source": [
        "# Generate m=50 pairs of populations, all with the same\n",
        "# average between the populations (the null hypothesis is true)\n",
        "w1, w2, _ = generate_dataset(n_datasets=50, n_null_true=50)\n",
        "pvalues = apply_ttest(w1, w2)\n",
        "\n",
        "print(\"Null hyp. is deemed %s\" % null_hyp_status(pvalues, alpha))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "PGFkCBFeFsVh"
      },
      "source": [
        "At first this result might come as a suprise. After all, we know that the null hypothesis is true!\n",
        "\n",
        "However, if you recall the definition of Type I error probability, by fixing $\\alpha=0.05$ we are setting up the test so that it will wrongly reject the null with 5% probability. Therefore, by repeating the test 50 times (one for each pair) we had each time a 5% chance of a type I error. The probability of having at least a rejection is hence given by the [Binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-oyBvBNFsVi",
        "outputId": "3c46a29b-b5bd-47df-dbe0-01988f6430ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prob. of >= 1 false positives in 50 trials is 0.923\n"
          ]
        }
      ],
      "source": [
        "# probability of having one or more rejections in 50 trials\n",
        "m = 50\n",
        "\n",
        "binomial_distr = scipy.stats.binom(m, alpha)\n",
        "\n",
        "# NOTE:  gives the probability cumulative of obtaining <= 0,\n",
        "# while we need >= 1, so we sub 1 - CDF(0)\n",
        "prob = 1-binomial_distr.cdf(0)\n",
        "\n",
        "print(\"The prob. of >= 1 false positives in %i \"\n",
        "      \"trials is %.3f\" % (m, prob))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "xqPp0VYQFsVi"
      },
      "source": [
        "There is over 90% chance to get at least one false positive in our setup. Testing multiple times an hypothesis as part of the same question is called \"multiple testing\" and require some more thoughts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1.4 Bonferroni / Sidak correction\n"
      ],
      "metadata": {
        "id": "22NXTcJ442Xd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Bonferroni (1936) introduced a simple correction for situations like this. The prescription is to substitute $\\alpha$ for each one of the $m$ independent tests within the composite test with a corrected type I error probability given by the Sidak formula $\\alpha^{\\prime} = 1 - (1-\\alpha)^{1/m}$ (which for large $m$ is often approximated with $\\alpha^{\\prime} = \\alpha / m$). \n",
        "\n",
        "> Sometimes in the literature the correction $\\alpha^{\\prime}=\\alpha / m$ is called \"Bonferroni correction\" while the correction $\\alpha^{\\prime} = 1 - (1-\\alpha)^{1/m}$ is called \"Sidak correction\". Here we will use the latter formulation, but use the name interceangably as the difference is very small for all practical purposes\n",
        "\n",
        "> NOTE: we assume independent tests. If there is correlation between the different tests, the methods presented here might or might not apply, you need to look closer at the relevant papers.\n",
        "\n",
        "Let's see if this solves our problem. We just need to change the criterium used to decide whether to reject or not the null, no need to change the computation of the p-values:"
      ],
      "metadata": {
        "id": "cTv4-3c-44iZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIQpqqlNFsVi",
        "outputId": "1b672eb9-4742-4e26-e3c9-dfb2374addac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null hyp. is deemed True\n"
          ]
        }
      ],
      "source": [
        "# Test if any of the pvalues is lower than alpha',\n",
        "# if the answer yes, the null hyp. is deemed False\n",
        "def null_hyp_status_bonferroni(pvalues, alpha):\n",
        "    \n",
        "    # Number of tests\n",
        "    m = pvalues.shape[0]\n",
        "    \n",
        "    # Bonferroni/Sidak correction\n",
        "    alpha_prime = 1 - (1-alpha)**(1.0/m)\n",
        "    \n",
        "    # Test whether *all* null hypothesis in the subtests are\n",
        "    # true or not\n",
        "    return np.all(pvalues > alpha_prime)\n",
        "\n",
        "w1, w2, _ = generate_dataset(n_datasets=50, n_null_true=50)\n",
        "pvalues = apply_ttest(w1, w2)\n",
        "\n",
        "print(\"Null hyp. is deemed %s\" % null_hyp_status_bonferroni(pvalues, alpha))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "8Fq1UTDcFsVi"
      },
      "source": [
        "That looks better. In order to make sure, let's generate a lot of synthetic datasets as earlier and let's see if our Bonferroni-corrected test provides the nominal type I error probability $\\alpha=0.05$:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now apply the test\n",
        "alpha = 0.05\n",
        "\n",
        "# Times the test was rejected\n",
        "rejected = 0\n",
        "\n",
        "# Number of iterations\n",
        "iter = 5000\n",
        "\n",
        "for i in range(iter):\n",
        "    seed = (i+1) * 1000\n",
        "    w1, w2, ground_truth = generate_dataset(n_datasets=50, n_null_true=50, seed=seed)\n",
        "\n",
        "    pvalue = apply_ttest(w1, w2)\n",
        "\n",
        "    if not null_hyp_status_bonferroni(pvalue, alpha):\n",
        "        rejected += 1\n",
        "\n",
        "print(\"\\nMeasured chance probability of rejecting the \"\n",
        "      \"null: %.3f (should be %.3f)\" % (rejected/iter, alpha))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka3l2Mq9Gaah",
        "outputId": "a181b34a-bfbc-490e-e218-d239825477e1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Measured chance probability of rejecting the null: 0.047 (should be 0.050)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "2ti44Bt4FsVi"
      },
      "source": [
        "It worked. The type I error probability is indeed very close to the nominal 5%."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Example_07_Multiple_Hypothesis_testing.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}