{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 08 - Decision Trees Example 02.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I4pgzLVtBTP"
      },
      "source": [
        "# 1.0 An end-to-end classification problem\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh34gim6KPtT"
      },
      "source": [
        "## 1.1 Dataset description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE8OJoDZ5AFK"
      },
      "source": [
        "\n",
        "\n",
        "We'll be looking at individual income in the United States. The **data** is from the **1994 census**, and contains information on an individual's **marital status**, **age**, **type of work**, and more. The **target column**, or what we want to predict, is whether individuals make less than or equal to 50k a year, or more than **50k a year**.\n",
        "\n",
        "You can download the data from the [University of California, Irvine's website](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UpxKxU1Ej7f"
      },
      "source": [
        "## 1.2 Load Libraries, Train and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT3UYjmT9KlL"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YAxtXO7tFvo"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login --relogin"
      ],
      "metadata": {
        "id": "UH7EG6dX-X0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save_code tracking all changes of the notebook and sync with Wandb\n",
        "run = wandb.init(project=\"Week08_Example_02\")"
      ],
      "metadata": {
        "id": "fkclIcNO-f4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_path = run.use_artifact(\"week_07_data_segregation/train_data.csv:latest\").file()\n",
        "df_train = pd.read_csv(local_path)"
      ],
      "metadata": {
        "id": "1OUlGInp-lC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "AytDrZpM42t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-DUXVHX6b3v"
      },
      "source": [
        "## 1.3 Train and Dev split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpzYMp3pCvfp"
      },
      "source": [
        "# split-out train/validation and test dataset\n",
        "x_train, x_val, y_train, y_val = train_test_split(df_train.drop(labels=\"high_income\",axis=1),\n",
        "                                                    df_train[\"high_income\"],\n",
        "                                                    test_size=0.30,\n",
        "                                                    random_state=41,\n",
        "                                                    shuffle=True,\n",
        "                                                    stratify=df_train[\"high_income\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8S6amWMwvKb"
      },
      "source": [
        "print(\"x train: {}\".format(x_train.shape))\n",
        "print(\"y train: {}\".format(y_train.shape))\n",
        "print(\"x val: {}\".format(x_val.shape))\n",
        "print(\"y val: {}\".format(y_val.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVSp2519_WDo"
      },
      "source": [
        "## 1.4 Removal Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GpD1w8h_Zas"
      },
      "source": [
        "# Verify if columns[int64] has outliers (without data leakage!!!!!!!)\n",
        "\n",
        "# data\n",
        "x = x_train.select_dtypes(\"int64\").copy()\n",
        "\n",
        "# identify outlier in the dataset\n",
        "lof = LocalOutlierFactor()\n",
        "outlier = lof.fit_predict(x)\n",
        "mask = outlier != -1\n",
        "\n",
        "print(\"X_train shape [original]: {}\".format(x_train.shape))\n",
        "print(\"X_train shape [outlier removal]: {}\".format(x_train.loc[mask,:].shape))\n",
        "\n",
        "# income with outliner\n",
        "x_train = x_train.loc[mask,:].copy()\n",
        "y_train = y_train[mask].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq2ceB9C6gwr"
      },
      "source": [
        "## 1.5 Encoding target variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xII7rHrixqhA"
      },
      "source": [
        "If a categorical target variable needs to be encoded for a classification predictive modeling problem, then the [LabelEncoder class](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) can be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK2JZqj4xyGe"
      },
      "source": [
        "# define a categorical encoding for target variable\n",
        "le = LabelEncoder()\n",
        "\n",
        "# fit and transoform y_train\n",
        "y_train = le.fit_transform(y_train)\n",
        "\n",
        "# transform y_test (avoiding data leakage)\n",
        "y_val = le.transform(y_val)\n",
        "\n",
        "print(\"Classes: {}\".format(le.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NKn5vCtzD6E"
      },
      "source": [
        "# just in case you need the inverse transformation\n",
        "le.inverse_transform([0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZcYQYHSyr6l"
      },
      "source": [
        "# sampling of transformed target variable\n",
        "print(y_train[:5],y_val[-6:-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1HmpavdyEZI"
      },
      "source": [
        "## 1.6 Pipeline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Lbzn2vyOxI"
      },
      "source": [
        "### 1.6.1 Column extractor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRlGD305yK-8"
      },
      "source": [
        "#Custom Transformer that extracts columns passed as argument to its constructor \n",
        "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
        "    #Class Constructor \n",
        "    def __init__( self, feature_names ):\n",
        "        self.feature_names = feature_names \n",
        "    \n",
        "    #Return self nothing else to do here    \n",
        "    def fit( self, X, y = None ):\n",
        "        return self \n",
        "    \n",
        "    #Method that describes what we need this transformer to do\n",
        "    def transform( self, X, y = None ):\n",
        "        return X[ self.feature_names ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O2SsQeVyhFv"
      },
      "source": [
        "### 1.6.2 Categorical transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTb4zixxyeuF"
      },
      "source": [
        "# Handling categorical features \n",
        "class CategoricalTransformer( BaseEstimator, TransformerMixin ):\n",
        "  # Class constructor method that takes one boolean as its argument\n",
        "  def __init__(self, new_features=True):\n",
        "    self.new_features = new_features\n",
        "    self.colnames = None\n",
        "\n",
        "  #Return self nothing else to do here    \n",
        "  def fit( self, X, y = None ):\n",
        "    return self \n",
        "\n",
        "  def get_feature_names(self):\n",
        "        return self.colnames.tolist()\n",
        "\n",
        "  # Transformer method we wrote for this transformer \n",
        "  def transform(self, X , y = None ):\n",
        "    df = X.copy()\n",
        "\n",
        "    # customize feature?\n",
        "    # how can I identify this one? EDA!!!!\n",
        "    if self.new_features: \n",
        "      \n",
        "      # minimize the cardinality of native_country feature\n",
        "      df.loc[df['native_country']!=' United-States','native_country'] = 'non_usa' \n",
        "\n",
        "      # replace ? with Unknown\n",
        "      edit_cols = ['native_country','occupation','workclass']\n",
        "      for col in edit_cols:\n",
        "        df.loc[df[col] == ' ?', col] = 'unknown'\n",
        "\n",
        "      # decrease the cardinality of education feature\n",
        "      hs_grad = [' HS-grad',' 11th',' 10th',' 9th',' 12th']\n",
        "      elementary = [' 1st-4th',' 5th-6th',' 7th-8th']\n",
        "      # replace\n",
        "      df['education'].replace(to_replace = hs_grad,value = 'HS-grad',inplace = True)\n",
        "      df['education'].replace(to_replace = elementary,value = 'elementary_school',inplace = True)\n",
        "\n",
        "      # adjust marital_status feature\n",
        "      married= [' Married-spouse-absent',' Married-civ-spouse',' Married-AF-spouse']\n",
        "      separated = [' Separated',' Divorced']\n",
        "      # replace \n",
        "      df['marital_status'].replace(to_replace = married ,value = 'Married',inplace = True)\n",
        "      df['marital_status'].replace(to_replace = separated,value = 'Separated',inplace = True)\n",
        "\n",
        "      # adjust workclass feature\n",
        "      self_employed = [' Self-emp-not-inc',' Self-emp-inc']\n",
        "      govt_employees = [' Local-gov',' State-gov',' Federal-gov']\n",
        "      # replace elements in list.\n",
        "      df['workclass'].replace(to_replace = self_employed ,value = 'Self_employed',inplace = True)\n",
        "      df['workclass'].replace(to_replace = govt_employees,value = 'Govt_employees',inplace = True)\n",
        "\n",
        "    # update column names\n",
        "    self.colnames = df.columns      \n",
        "  \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ74X1pT6zSy"
      },
      "source": [
        "#### 1.6.2.1 Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz2WX53svcKK"
      },
      "source": [
        "# \n",
        "# for validation purposes\n",
        "#\n",
        "model = FeatureSelector(x_train.select_dtypes(\"object\").columns.to_list())\n",
        "df = model.fit_transform(x_train)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz_lSNabr-vo"
      },
      "source": [
        "# \n",
        "# for validation purposes\n",
        "#\n",
        "model = CategoricalTransformer(new_features=True)\n",
        "df_cat = model.fit_transform(df)\n",
        "df_cat.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd4sWYhGOpmp"
      },
      "source": [
        "# check the cardinality before and after transformation\n",
        "x_train.select_dtypes(\"object\").apply(pd.Series.nunique)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcQ0UgLJOiRL"
      },
      "source": [
        "# check the cardinality before and after transformation\n",
        "df_cat.apply(pd.Series.nunique)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8iPHaNO39WK"
      },
      "source": [
        "### 1.6.3 Numerical transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAjVuX4T6RdO"
      },
      "source": [
        "# transform numerical features\n",
        "class NumericalTransformer( BaseEstimator, TransformerMixin ):\n",
        "  # Class constructor method that takes a model parameter as its argument\n",
        "  # model 0: minmax\n",
        "  # model 1: standard\n",
        "  # model 2: without scaler\n",
        "  def __init__(self, model = 0):\n",
        "    self.model = model\n",
        "    self.colnames = None\n",
        "\n",
        "  #Return self nothing else to do here    \n",
        "  def fit( self, X, y = None ):\n",
        "    return self\n",
        "\n",
        "  # return columns names after transformation\n",
        "  def get_feature_names(self):\n",
        "        return self.colnames \n",
        "        \n",
        "  #Transformer method we wrote for this transformer \n",
        "  def transform(self, X , y = None ):\n",
        "    df = X.copy()\n",
        "    \n",
        "    # update columns name\n",
        "    self.colnames = df.columns.tolist()\n",
        "    \n",
        "    # minmax\n",
        "    if self.model == 0: \n",
        "      scaler = MinMaxScaler()\n",
        "      # transform data\n",
        "      df = scaler.fit_transform(df)\n",
        "    elif self.model == 1:\n",
        "      scaler = StandardScaler()\n",
        "      # transform data\n",
        "      df = scaler.fit_transform(df)\n",
        "    else:\n",
        "      df = df.values\n",
        "\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQNWkR579Gqe"
      },
      "source": [
        "#### 1.6.3.1 Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdC-TA3J9JLh"
      },
      "source": [
        "# \n",
        "# for validation purposes\n",
        "#\n",
        "model = FeatureSelector(x_train.select_dtypes(\"int64\").columns.to_list())\n",
        "df = model.fit_transform(x_train)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_xkXWNz9reF"
      },
      "source": [
        "# \n",
        "# for validation purposes\n",
        "# \n",
        "# model 0: minmax\n",
        "# model 1: standard\n",
        "# model 2: without scaler\n",
        "#\n",
        "model = NumericalTransformer(model=1)\n",
        "df_cat = model.fit_transform(df)\n",
        "df_cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec_37RWJ-1_b"
      },
      "source": [
        "### 1.6.4 Pipeline union (cat + num)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAKNrKbi--5I"
      },
      "source": [
        "# Categrical features to pass down the categorical pipeline \n",
        "categorical_features = x_train.select_dtypes(\"object\").columns.to_list()\n",
        "\n",
        "# Numerical features to pass down the numerical pipeline \n",
        "numerical_features = x_train.select_dtypes(\"int64\").columns.to_list()\n",
        "\n",
        "# Defining the steps in the categorical pipeline \n",
        "categorical_pipeline = Pipeline(steps = [('cat_selector', FeatureSelector(categorical_features)),\n",
        "                                         ('cat_transformer', CategoricalTransformer()),\n",
        "                                         #('cat_encoder','passthrough')\n",
        "                                         ('cat_encoder',OneHotEncoder(sparse=False,drop=\"first\"))\n",
        "                                         ]\n",
        "                                )\n",
        "\n",
        "# Defining the steps in the numerical pipeline     \n",
        "numerical_pipeline = Pipeline(steps = [('num_selector', FeatureSelector(numerical_features)),\n",
        "                                       ('num_transformer', NumericalTransformer()) \n",
        "                                       ]\n",
        "                              )\n",
        "\n",
        "# Combining numerical and categorical piepline into one full big pipeline horizontally \n",
        "# using FeatureUnion\n",
        "full_pipeline_preprocessing = FeatureUnion(transformer_list = [('cat_pipeline', categorical_pipeline),\n",
        "                                                               ('num_pipeline', numerical_pipeline)\n",
        "                                                               ]\n",
        "                                           )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIq1_UaJ_7YV"
      },
      "source": [
        "#### 1.6.4.1 Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT4lDS75_99D"
      },
      "source": [
        "# \n",
        "# for validate purposes\n",
        "#\n",
        "new_data = full_pipeline_preprocessing.fit_transform(x_train)\n",
        "catnames = full_pipeline_preprocessing.get_params()[\"cat_pipeline\"][2].get_feature_names_out().tolist()\n",
        "numnames = full_pipeline_preprocessing.get_params()[\"num_pipeline\"][1].get_feature_names()\n",
        "df = pd.DataFrame(new_data,columns = catnames + numnames)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Caaygz8Oy8kw"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EBxTF3SAlm7"
      },
      "source": [
        "## 1.7 Modeling and Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The full pipeline \n",
        "pipe = Pipeline(steps = [('full_pipeline', full_pipeline_preprocessing),\n",
        "                         (\"classifier\",DecisionTreeClassifier())])\n",
        "\n",
        "# training \n",
        "pipe.fit(x_train,y_train)\n",
        "\n",
        "# final model\n",
        "predict = pipe.predict(x_val)"
      ],
      "metadata": {
        "id": "Qtvg28TjMEKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix (we change the way to make equal to slides)\n",
        "#             true label\n",
        "#               1     0     \n",
        "# predict  1    TP    FP\n",
        "#          0    FN    TN\n",
        "#\n",
        "\n",
        "confusion_matrix(predict,y_val,\n",
        "                 labels=[1,0])"
      ],
      "metadata": {
        "id": "Vb_8k4J4Md2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_val, predict))\n",
        "print(classification_report(y_val,predict))"
      ],
      "metadata": {
        "id": "9P5favFdMl8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(7,4))\n",
        "\n",
        "ConfusionMatrixDisplay(confusion_matrix(predict,y_val,labels=[1,0]),\n",
        "                       display_labels=[\">50k\",\"<=50k\"],).plot(values_format=\".0f\",ax=ax)\n",
        "\n",
        "ax.set_xlabel(\"True Label\")\n",
        "ax.set_ylabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_xsc5ABpMhzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_val, predict, average=\"macro\")"
      ],
      "metadata": {
        "id": "XAl_ie3PMsdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full pipeline\n",
        "features_full = pipe.named_steps['full_pipeline']\n",
        "\n",
        "# get columns names from categorial columns\n",
        "features_cat = features_full.get_params()[\"cat_pipeline\"]\n",
        "features_cat = features_cat[2].get_feature_names_out().tolist()\n",
        "features_cat"
      ],
      "metadata": {
        "id": "DNwbgo9jOVLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get columns names from numerical columns\n",
        "features_num = features_full.get_params()[\"num_pipeline\"][1].get_feature_names()\n",
        "features_num"
      ],
      "metadata": {
        "id": "1z9m72SjOpSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree # to draw a classification tree\n",
        "fig, ax = plt.subplots(1,1, figsize=(15, 10))\n",
        "plot_tree(pipe[\"classifier\"], \n",
        "          filled=True, \n",
        "          rounded=True, \n",
        "          class_names=[\"<=50k\", \">50k\"],\n",
        "          feature_names=features_cat+features_num, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9bkdiltrNrrv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}